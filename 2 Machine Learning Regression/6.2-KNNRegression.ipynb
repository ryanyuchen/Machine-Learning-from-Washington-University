{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting house prices using k-nearest neighbors regression\n",
    "In this notebook, you will implement k-nearest neighbors regression. You will:\n",
    "  * Find the k-nearest neighbors of a given query input\n",
    "  * Predict the output for the query input using the k-nearest neighbors\n",
    "  * Choose the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>5650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>7639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>8062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>7503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8698</th>\n",
       "      <td>0844000965</td>\n",
       "      <td>20140626T000000</td>\n",
       "      <td>224000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>11968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98010</td>\n",
       "      <td>47.3095</td>\n",
       "      <td>-122.002</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>11303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8699</th>\n",
       "      <td>7852140040</td>\n",
       "      <td>20140825T000000</td>\n",
       "      <td>507250.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2270.0</td>\n",
       "      <td>5536</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2270</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98065</td>\n",
       "      <td>47.5389</td>\n",
       "      <td>-121.881</td>\n",
       "      <td>2270.0</td>\n",
       "      <td>5731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8700</th>\n",
       "      <td>9834201367</td>\n",
       "      <td>20150126T000000</td>\n",
       "      <td>429000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1126</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1490</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5699</td>\n",
       "      <td>-122.288</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8701</th>\n",
       "      <td>3448900210</td>\n",
       "      <td>20141014T000000</td>\n",
       "      <td>610685.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>6023</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2520</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98056</td>\n",
       "      <td>47.5137</td>\n",
       "      <td>-122.167</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>6023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>0263000018</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>1509.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8703 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0     7129300520  20141013T000000  221900.0       3.0       1.00       1180.0   \n",
       "1     6414100192  20141209T000000  538000.0       3.0       2.25       2570.0   \n",
       "2     5631500400  20150225T000000  180000.0       2.0       1.00        770.0   \n",
       "3     2487200875  20141209T000000  604000.0       4.0       3.00       1960.0   \n",
       "4     1954400510  20150218T000000  510000.0       3.0       2.00       1680.0   \n",
       "...          ...              ...       ...       ...        ...          ...   \n",
       "8698  0844000965  20140626T000000  224000.0       3.0       1.75       1500.0   \n",
       "8699  7852140040  20140825T000000  507250.0       3.0       2.50       2270.0   \n",
       "8700  9834201367  20150126T000000  429000.0       3.0       2.00       1490.0   \n",
       "8701  3448900210  20141014T000000  610685.0       4.0       2.50       2520.0   \n",
       "8702  0263000018  20140521T000000  360000.0       3.0       2.50       1530.0   \n",
       "\n",
       "      sqft_lot  floors  waterfront  view  ...  grade  sqft_above  \\\n",
       "0         5650     1.0           0     0  ...      7        1180   \n",
       "1         7242     2.0           0     0  ...      7        2170   \n",
       "2        10000     1.0           0     0  ...      6         770   \n",
       "3         5000     1.0           0     0  ...      7        1050   \n",
       "4         8080     1.0           0     0  ...      8        1680   \n",
       "...        ...     ...         ...   ...  ...    ...         ...   \n",
       "8698     11968     1.0           0     0  ...      6        1500   \n",
       "8699      5536     2.0           0     0  ...      8        2270   \n",
       "8700      1126     3.0           0     0  ...      8        1490   \n",
       "8701      6023     2.0           0     0  ...      9        2520   \n",
       "8702      1131     3.0           0     0  ...      8        1530   \n",
       "\n",
       "      sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0                 0      1955             0    98178  47.5112 -122.257   \n",
       "1               400      1951          1991    98125  47.7210 -122.319   \n",
       "2                 0      1933             0    98028  47.7379 -122.233   \n",
       "3               910      1965             0    98136  47.5208 -122.393   \n",
       "4                 0      1987             0    98074  47.6168 -122.045   \n",
       "...             ...       ...           ...      ...      ...      ...   \n",
       "8698              0      2014             0    98010  47.3095 -122.002   \n",
       "8699              0      2003             0    98065  47.5389 -121.881   \n",
       "8700              0      2014             0    98144  47.5699 -122.288   \n",
       "8701              0      2014             0    98056  47.5137 -122.167   \n",
       "8702              0      2009             0    98103  47.6993 -122.346   \n",
       "\n",
       "      sqft_living15  sqft_lot15  \n",
       "0            1340.0      5650.0  \n",
       "1            1690.0      7639.0  \n",
       "2            2720.0      8062.0  \n",
       "3            1360.0      5000.0  \n",
       "4            1800.0      7503.0  \n",
       "...             ...         ...  \n",
       "8698         1320.0     11303.0  \n",
       "8699         2270.0      5731.0  \n",
       "8700         1400.0      1230.0  \n",
       "8701         2520.0      6023.0  \n",
       "8702         1530.0      1509.0  \n",
       "\n",
       "[8703 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales = pd.read_csv('kc_house_data_small.csv', dtype=dtype_dict)\n",
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import useful functions from previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data_frame, features, output):\n",
    "    data_frame['constant'] = 1 # this is how you add a constant column to data frame\n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "\n",
    "    # the following line will convert the features and output into a numpy matrix:\n",
    "    features_df = data_frame[features]\n",
    "    feature_matrix = features_df.to_numpy()\n",
    "   \n",
    "    output_df = data_frame[output]\n",
    "    output_array = output_df.to_numpy()\n",
    "\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    norms = np.linalg.norm(feature_matrix, axis=0)\n",
    "    normalized_features = feature_matrix/norms\n",
    "    return normalized_features, norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training, test, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('kc_house_data_small_test.csv', dtype=dtype_dict)\n",
    "training = pd.read_csv('kc_house_data_small_train.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('kc_house_data_validation.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['bedrooms',  \n",
    "                'bathrooms',  \n",
    "                'sqft_living',  \n",
    "                'sqft_lot',  \n",
    "                'floors',\n",
    "                'waterfront',  \n",
    "                'view',  \n",
    "                'condition',  \n",
    "                'grade',  \n",
    "                'sqft_above',  \n",
    "                'sqft_basement',\n",
    "                'yr_built',  \n",
    "                'yr_renovated',  \n",
    "                'lat',  \n",
    "                'long',  \n",
    "                'sqft_living15',  \n",
    "                'sqft_lot15']\n",
    "\n",
    "features_train, output_train = get_numpy_data(training, feature_list, 'price')\n",
    "features_test, output_test = get_numpy_data(testing, feature_list, 'price')\n",
    "features_valid, output_valid = get_numpy_data(validation, feature_list, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computing distances, it is crucial to normalize features. Otherwise, for example, the `sqft_living` feature (typically on the order of thousands) would exert a much larger influence on distance than the `bedrooms` feature (typically on the order of ones). We divide each column of the training feature matrix by its 2-norm, so that the transformed column has unit norm.\n",
    "\n",
    "IMPORTANT: Make sure to store the norms of the features in the training set. The features in the test and validation sets must be divided by these same norms, so that the training, test, and validation sets are normalized consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, norms = normalize_features(features_train) # normalize training set features (columns)\n",
    "features_test = features_test / norms # normalize test set by training set norms\n",
    "features_valid = features_valid / norms # normalize validation set by training set norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute a single distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's just explore computing the \"distance\" between two given houses.  We will take our **query house** to be the first house of the test set and look at the distance between this house and the 10th house of the training set.\n",
    "\n",
    "To see the features associated with the query house, print the first row (index 0) of the test feature matrix. You should get an 18-dimensional vector whose components are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01345102,  0.01551285,  0.01807473,  0.01759212,  0.00160518,\n",
       "        0.017059  ,  0.        ,  0.05102365,  0.0116321 ,  0.01564352,\n",
       "        0.01362084,  0.02481682,  0.01350306,  0.        ,  0.01345387,\n",
       "       -0.01346922,  0.01375926,  0.0016225 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01345102,  0.01163464,  0.00602491,  0.0083488 ,  0.00050756,\n",
       "        0.01279425,  0.        ,  0.        ,  0.01938684,  0.01390535,\n",
       "        0.0096309 ,  0.        ,  0.01302544,  0.        ,  0.01346821,\n",
       "       -0.01346251,  0.01195898,  0.00156612])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the Euclidean distance between the query house and the 10th house of the training set? \n",
    "\n",
    "Note: Do not use the `np.linalg.norm` function; use `np.sqrt`, `np.sum`, and the power operator (`**`) instead. The latter approach is more easily adapted to computing multiple distances at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05972359371398078"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(sum((features_test[0]-features_train[9])**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute multiple distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, to do nearest neighbor regression, we need to compute the distance between our query house and *all* houses in the training set.  \n",
    "\n",
    "To visualize this nearest-neighbor search, let's first compute the distance from our query house (`features_test[0]`) to the first 10 houses of the training set (`features_train[0:10]`) and then search for the nearest neighbor within this small set of houses.  Through restricting ourselves to a small set of houses to begin with, we can visually scan the list of 10 distances to verify that our code for finding the nearest neighbor is working.\n",
    "\n",
    "Write a loop to compute the Euclidean distance from the query house to each of the first 10 houses in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06027470916295592\n",
      "0.08546881147643746\n",
      "0.06149946435279315\n",
      "0.05340273979294363\n",
      "0.05844484060170442\n",
      "0.059879215098128345\n",
      "0.05463140496775461\n",
      "0.05543108323614607\n",
      "0.052383627840220305\n",
      "0.05972359371398078\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    d = np.sqrt(sum((features_test[0]-features_train[i])**2))\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform 1-nearest neighbor regression\n",
    "\n",
    "Now that we have the element-wise differences, it is not too hard to compute the Euclidean distances between our query house and all of the training houses. First, write a single-line expression to define a variable `diff` such that `diff[i]` gives the element-wise difference between the features of the query house and the `i`-th training house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.09343399874654643\n"
     ]
    }
   ],
   "source": [
    "diff = features_train[:] - features_test[0]\n",
    "print(diff[-1].sum()) # sum of the feature differences between the query and last training house\n",
    "# should print -0.0934339605842"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in computing the Euclidean distances is to take these feature-by-feature differences in `diff`, square each, and take the sum over feature indices.  That is, compute the sum of square feature differences for each training house (row in `diff`).\n",
    "\n",
    "By default, `np.sum` sums up everything in the matrix and returns a single number. To instead sum only over a row or column, we need to specifiy the `axis` parameter described in the `np.sum` [documentation](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.sum.html). In particular, `axis=1` computes the sum across each row.\n",
    "\n",
    "Below, we compute this sum of square feature differences for all training houses and verify that the output for the 16th house in the training set is equivalent to having examined only the 16th row of `diff` and computing the sum of squares on that row alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0033070590284564457\n",
      "0.0033070590284564453\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(diff**2, axis=1)[15]) # take sum of squares across each row, and print the 16th sum\n",
    "print(np.sum(diff[15]**2)) # print the sum of squares for the 16th row -- should be same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this result in mind, write a single-line expression to compute the Euclidean distances between the query house and all houses in the training set. Assign the result to a variable `distances`.\n",
    "\n",
    "**Hint**: Do not forget to take the square root of the sum of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06027471 0.08546881 0.06149946 ... 0.05716729 0.05705739 0.05846758]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3758"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = np.sqrt(np.sum(diff**2, axis=1))\n",
    "print(distances)\n",
    "distances.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635000.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_train[3758]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform k-nearest neighbor regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For k-nearest neighbors, we need to find a *set* of k houses in the training set closest to a given query house. We then make predictions based on these k nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch k-nearest neighbors\n",
    "\n",
    "Using the functions above, implement a function that takes in\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses; and\n",
    " * the feature vector of the query house\n",
    " \n",
    "and returns the indices of the k closest training houses. For instance, with 2-nearest neighbor, a return value of [5, 10] would indicate that the 6th and 11th training houses are closest to the query house.\n",
    "\n",
    "**Hint**: Look at the [documentation for `np.argsort`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5038"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = distances.argsort()\n",
    "list[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a single prediction by averaging k nearest neighbor outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to find the k-nearest neighbors, write a function that predicts the value of a given query house. **For simplicity, take the average of the prices of the k nearest neighbors in the training set**. The function should have the following parameters:\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses;\n",
    " * the output values (prices) of the training houses; and\n",
    " * the feature vector of the query house, whose price we are predicting.\n",
    " \n",
    "The function should return a predicted value of the query house.\n",
    "\n",
    "**Hint**: You can extract multiple items from a Numpy array using a list of indices. For instance, `output_train[[6, 10]]` returns the prices of the 7th and 11th training houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k, features_train, output_train, features_query):\n",
    "    diff = features_train[:] - features_query\n",
    "    distance = np.sqrt(np.sum(diff**2, axis=1))\n",
    "    list = distance.argsort()\n",
    "    result = 0\n",
    "    \n",
    "    for i in range(k):\n",
    "        result += output_train[list[i]]\n",
    "    \n",
    "    return result/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413987.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn(4, features_train, output_train, features_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make multiple predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to predict the value of *each and every* house in a query set. (The query set can be any subset of the dataset, be it the test set or validation set.) The idea is to have a loop where we take each house in the query set as the query house and make a prediction for that specific house. The new function should take the following parameters:\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses;\n",
    " * the output values (prices) of the training houses; and\n",
    " * the feature matrix for the query set.\n",
    " \n",
    "The function should return a set of predicted values, one for each house in the query set.\n",
    "\n",
    "**Hint**: To get the number of houses in the query set, use the `.shape` field of the query features matrix. See [the documentation](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.ndarray.shape.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_all(k, features_train_matrix, output_train_matrix, features_test_matrix, n):\n",
    "    for i in range(n): \n",
    "        result = knn(10, features_train_matrix, output_train_matrix, features_test_matrix[i])\n",
    "        print([i,result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 881300.0]\n",
      "[1, 431860.0]\n",
      "[2, 460595.0]\n",
      "[3, 430200.0]\n",
      "[4, 766750.0]\n",
      "[5, 667420.0]\n",
      "[6, 350032.0]\n",
      "[7, 512800.7]\n",
      "[8, 484000.0]\n",
      "[9, 457235.0]\n"
     ]
    }
   ],
   "source": [
    "knn_all(10,features_train, output_train, features_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There remains a question of choosing the value of k to use in making predictions. Here, we use a validation set to choose this value. Write a loop that does the following:\n",
    "\n",
    "* For `k` in [1, 2, ..., 15]:\n",
    "    * Makes predictions for each house in the VALIDATION set using the k-nearest neighbors from the TRAINING set.\n",
    "    * Computes the RSS for these predictions on the VALIDATION set\n",
    "    * Stores the RSS computed above in `rss_all`\n",
    "* Report which `k` produced the lowest RSS on VALIDATION set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1.05453830251561]\n",
      "[2, 0.834450735040255]\n",
      "[3, 0.726920960192028]\n",
      "[4, 0.7194672165209168]\n",
      "[5, 0.6984651741971859]\n",
      "[6, 0.688995443531811]\n",
      "[7, 0.6834197345005105]\n",
      "[8, 0.673616787354915]\n",
      "[9, 0.6837272795897633]\n",
      "[10, 0.693350486685567]\n",
      "[11, 0.6952385521559887]\n",
      "[12, 0.6904996958724645]\n",
      "[13, 0.7001125450826362]\n",
      "[14, 0.7090869886903444]\n",
      "[15, 0.7110692838594536]\n"
     ]
    }
   ],
   "source": [
    "rss_all=[]\n",
    "for k in range(1,16):\n",
    "    rss=0\n",
    "    for i in range(features_valid.shape[0]):\n",
    "        predict = knn(k, features_train, output_train, features_valid[i])\n",
    "        rss = rss + (predict-output_valid[i])**2    \n",
    "    rss_all.append(rss)\n",
    "    \n",
    "    print([k, rss*1E-14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x252b8e91288>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "kvals = range(1, 16)\n",
    "plt.plot(kvals, rss_all,'bo-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
